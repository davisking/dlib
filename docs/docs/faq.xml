<?xml version="1.0" encoding="ISO-8859-1"?>
<?xml-stylesheet type="text/xsl" href="stylesheet.xsl"?>

<doc>
   <title>Frequently Asked Questions</title>

   <!-- ************************************************************************* -->
   <questions group="General">

      <question text="It doesn't work?">
         Do not post a question like "I'm using dlib, and it doesn't work?" or
         "I'm using the object detector and it doesn't work, what do I do?".
         If this is all you say then I have no idea what is wrong.  99% of the
         time it's some kind of user error.  1% of the time it's some problem
         in dlib.  But again, without more information it's impossible to know.
         So please don't post questions like this.  

         <p>
         If you think you found some kind of bug or problem in dlib then feel
         free to submit a dlib issue on <a href="https://github.com/davisking/dlib/issues">github</a>.  
         But include the version of dlib you are using, what you
         are trying, what happened, what you expected to have happened instead, etc.
         </p>

         <p>
         On the other hand, if you haven't found a bug or problem in dlib, but
         instead are looking for machine learning/computer vision/programming
         help then post your question to <a href="http://stackoverflow.com/questions/tagged/dlib">stack overflow with the dlib tag</a>.
         </p>
      </question>

      <question text="How can I use dlib in Visual Studio?">
         There are instructions on the <a href="compile.html">How to Compile</a> page.  
         If you do not understand the instructions in the "<b>Compiling on Windows Using Visual Studio</b>" section
         or are getting errors then follow the instructions in the "<b>Compiling on Any Operating System Using CMake</b>"
         section.  In particular, <a href="http://www.cmake.org/download/">install CMake</a> and then type 
         these exact commands from within the root of the dlib distribution:  
<code_box>
cd examples
mkdir build
cd build
del /F /S /Q *
cmake ..
cmake --build . --config Release
</code_box>
         That should compile the dlib examples in visual studio.  The output executables will appear in the Release folder.
         The <tt>del /F /S /Q *</tt> command is to make sure you clear out any extraneous files you might have placed in 
         the build folder and is not necessary if build begins empty.
      </question>

      <!-- ****************************************** -->

      <question text="Why is dlib slow?">
         Dlib isn't slow.  I get this question many times a week and 95% of the time it's from someone
         using Visual Studio who has compiled their program in Debug mode rather than the optimized
         Release mode.  So if you are using Visual Studio then realize that Visual Studio has these two modes.  
         The default is Debug.  The mode is selectable via a drop down:
         <p><img src="vs_mode_1.png"/></p>
         Debug mode disables compiler optimizations.  So the program will be very slow if you run it in Debug mode.
         So click the drop down,
         <p><img src="vs_mode_2.png"/></p>
         and select Release.
         <p><img src="vs_mode_3.png"/></p>
         Then when you compile the program it will appear in a folder named Release rather than in a folder named Debug.  

         <br/>
         <br/>
         Finally, you can enable either SSE4 or AVX instruction use.  These will make certain operations much faster (e.g. face detection).
         You do this using <a href="http://www.cmake.org/download/">CMake</a>'s cmake-gui tool.  For example, if you execute
         these commands you will get the cmake-gui screen:
<code_box>
cd examples
mkdir build
cd build
cmake .. 
cmake-gui .
</code_box>
         Which looks like this:
         <p><img src="vs-cmake-gui.png"/></p>
         Where you can select SSE4 or AVX instruction use.  Then you click configure and then generate. After that
         when you build your visual studio project some things will be faster.
         
         Finally, note that AVX is a little bit faster than SSE4 but if your computer is fairly old it might
         not support it.  In that case, either buy a new computer or use SSE4
         instructions. 
      </question>

      <!-- ****************************************** -->



      <question text="How can I cite dlib?">
         If you use dlib in your research then please use the following citation:
         <br/>
         <br/>
Davis E. King. <a href="http://jmlr.csail.mit.edu/papers/volume10/king09a/king09a.pdf">Dlib-ml: A Machine Learning Toolkit</a>. 
   <i>Journal of Machine Learning Research</i> 10, pp. 1755-1758, 2009
         <br/>
         <pre>

@Article{dlib09,
  author = {Davis E. King},
  title = {Dlib-ml: A Machine Learning Toolkit},
  journal = {Journal of Machine Learning Research},
  year = {2009},
  volume = {10},
  pages = {1755-1758},
}
         </pre>
      </question>

      <!-- ****************************************** -->



      <question text="Why isn't serialization working?">
         Here are the possibilities:
         <ul>
            <li>You are using a file stream and forgot to put it into binary mode.  
               You need to do something like this:
<code_box>
std::ifstream fin("myfile", std::ios::binary);
</code_box>
or
<code_box>
std::ofstream fout("myfile", std::ios::binary);
</code_box>

If you don't give <tt>std::ios::binary</tt> then the iostream will mess with the binary data and cause serialization
to not work right.  
            </li>

            <br/>
            <li>The iostream is in a bad state.  You can check the state by calling <tt>mystream.good()</tt>.
            If it returns false then the stream is in an error state such as end-of-file or maybe it failed
            to do the I/O.  Also note that if you close a file stream and reopen it you might have to call
            <tt>mystream.clear()</tt> to clear out the error flags.
            </li>
         </ul>

      </question>
      <!-- ****************************************** -->

      <question text="How do I set the size of a matrix at runtime?">
         Long answer, read the <a href="matrix_ex.cpp.html">matrix example program</a>.
         <br/><br/>
         Short answer, here are some examples:
<code_box>
matrix&lt;double&gt; mat;
mat.set_size(4,5);

matrix&lt;double,0,1&gt; column_vect;
column_vect.set_size(6);

matrix&lt;double,0,1&gt; column_vect2(6);  // give size to constructor

matrix&lt;double,1&gt; row_vect;
row_vect.set_size(5);
</code_box>

      </question>
      <!-- ****************************************** -->

      <question text="Where is the documentation for &lt;object/function&gt;?">
         If you can't find something then check the <a href="term_index.html">index</a>.
         <br/><br/>
         Also, the bulk of the documentation can be found by following the 
         <more_details/> links.   
      </question>


      <!-- ****************************************** -->

      <question text="How does dlib interface with other libraries/tools?">
         There should never be anything in dlib that prevents you from using or 
         interacting with other libraries.  Moreover, there are some additional tools
         in dlib to make some interactions easier:  

         <ul>
            <li><b>BLAS and LAPACK libraries</b> are used by the <a href="linear_algebra.html#matrix">matrix</a>
            automatically if you <tt>#define</tt> DLIB_USE_BLAS and/or DLIB_USE_LAPACK and link against
            the appropriate library files.  Note that the CMakeLists.txt file that comes with dlib will
            do this for you automatically in many instances.</li><br/>

            <li><b>Armadillo and Eigen libraries</b> have matrix objects which can be converted into
            dlib matrix objects by calling dlib::mat() on them.</li><br/>

            <li><b>OpenCV</b> image objects can be converted into a form usable by dlib routines
            by using <a href="imaging.html#cv_image">cv_image</a>.  You can also convert from a
            dlib matrix or image to an OpenCV Mat using dlib::<a href="imaging.html#toMat">toMat</a>().</li><br/>

            <li><b>Google Protocol Buffers</b> can be serialized by the dlib 
            <a href="other.html#serialize">serialization</a> routines.  
            This means that, for example, you can pass protocol buffer objects through a 
            <a href="network.html#bridge">bridge</a>.
            </li><br/>

            <li><b>libpng and libjpeg</b> are used by <a
            href="imaging.html#load_image">load_image</a> whenever
            DLIB_PNG_SUPPORT and DLIB_JPEG_SUPPORT are defined respectively.
            You must also tell your compiler to link against these libraries to
            use them. However, CMake will try to link against them
            automatically if they are installed.</li><br/>

            <!--<li><b>FFTW</b> is used by the fft() and ifft() routines if you #define DLIB_USE_FFTW and
            link to fftw3.  Otherwise dlib uses its own slower default implementation.  </li><br/> -->

            <li><b>SQLite</b> is used by the <a href="other.html#database">database</a> object.  In
            fact, it is just a wrapper around SQLite's C interface which simplifies its use (e.g. 
            makes resource management use RAII).</li>

         </ul>
      </question>

   </questions>




   <!-- ************************************************************************* -->

   <questions group="Machine Learning">

      <question text="Why is RVM training is really slow?">
         The optimization algorithm is somewhat unpredictable.  Sometimes it is fast and 
         sometimes it is slow.  What usually makes it really slow is if you use a radial basis
         kernel and you set the gamma parameter to something too large.  This causes the
         algorithm to start using a whole lot of relevance vectors (i.e. basis vectors) which
         then makes it slow.  The algorithm is only fast as long as the number of relevance vectors
         remains small but it is hard to know beforehand if that will be the case.  
         <p>
            You should try <a href="ml.html#krr_trainer">kernel ridge regression</a> instead since it
            also doesn't take any parameters but is always very fast.
         </p>

      </question>

      <!-- ****************************************** -->

      <question text="Why is cross_validate_trainer_threaded() crashing?">
         This function makes a copy of your training data for each thread.  So you are probably running out
         of memory.  To avoid this, use the <a href="algorithms.html#randomly_subsample">randomly_subsample</a> function
         to reduce the amount of data you are using or use fewer threads. 
         <p>
            For example, you could reduce the amount of data by saying this:
<code_box>
// reduce to only 1000 samples
cross_validate_trainer_threaded(trainer, 
                                randomly_subsample(samples, 1000), 
                                randomly_subsample(labels,  1000), 
                                4,   // num folds
                                4);  // num threads
</code_box>
         </p>
      </question>

      <!-- ****************************************** -->

      <question text="How can I define a custom kernel?">
         See the <a href="using_custom_kernels_ex.cpp.html">Using Custom Kernels</a> example program.
      </question>

      <!-- ****************************************** -->

      <question text="Can you give advice on feature generation/kernel selection?">
         <p>
            Picking the right kernel all comes down to understanding your data, and obviously this is 
            highly dependent on your problem.  
         </p>

         <p>
            One thing that's sometimes useful is to plot each feature against the target value.  You can get an idea of 
            what your overall feature space looks like and maybe tell if a linear kernel is the right solution.  But 
            this still hides important information from you.  For example, imagine you have two diagonal lines which 
            are very close together and are both the same length.  Suppose one line is of the +1 class and the other is the -1 
            class.  Each feature (the x or y coordinate values) by itself tells you almost nothing about which class 
            a point belongs to but together they tell you everything you need to know.  
         </p>

         <p>
            On the other hand, if you know something about the data you are working with then you can also try and 
            generate your own features.  So for example, if your data is a bunch of images and you know that one 
            of your classes contains a lot of lines then you can make a feature that attempts to measure the number 
            of lines in an image using a hough transform or sobel edge filter or whatever.  Generally, try and 
            think up features which should be highly correlated with your target value.  A good way to do this is 
            to try and actually hand code N solutions to the problem using whatever you know about your data or 
            domain.  If you do a good job then you will have N really great features and a linear or rbf kernel 
            will probably do very well when using them.
         </p>

         <p>
            Or you can just try a whole bunch of kernels, kernel parameters, and training algorithm options while 
            using cross validation.  I.e. when in doubt, use brute force :)   There is an example of that kind of 
            thing in the <a href="model_selection_ex.cpp.html">model selection</a> example program. 
         </p>
      </question>

      <!-- ****************************************** -->

      <question text="Why does my decision_function always give the same output?">
         This happens when you use the radial_basis_kernel and you set the gamma value to
         something highly inappropriate.  To understand what's happening lets imagine your
         data has just one feature and its value ranges from 0 to 7.  Then what you want is a 
         gamma value that gives nice Gaussian bumps like the one in this graph: <br/>

         <center><image src="rbf_normal.gif"/></center>

         <br/>
         However, if you make gamma really huge you will get this (it's zero everywhere except for one place):
         <br/>
         <center><image src="rbf_big_gamma.gif"/></center>

         <br/>
         Or if you make gamma really small then it will be 1.0 everywhere:
         <br/>
         <center><image src="rbf_small_gamma.gif"/></center>

         <p>
            So you need to pick the gamma value so that it is scaled reasonably to your data.  A <i><font color="red">good rule of
            thumb (i.e. not the optimal gamma, just a heuristic guess)</font></i> is the following:
         </p>
         <code_box>const double gamma = 1.0/compute_mean_squared_distance(randomly_subsample(samples, 2000));</code_box>
           
      </question>

      <!-- ****************************************** -->

   </questions>

   <!-- ************************************************************************* -->

   <questions group="Deep Learning">
      <question text="Why can't I use DNN module with Visual Studio?">
         The deep learning toolkit in dlib requires a C++11 compiler.
         Unfortunately, as of July 2016, no versions of Visual Studio fully
         support C++11, so not all the deep learning code will compile.
         However, all the other modules in dlib can be used in Visual Studio
         without any trouble.
      </question>

      <question text="Why can't I change the network architecture at runtime?">
          A major design goal of this API is to let users create new loss
          layers, computational layers, and solvers without needing to
          understand or even look at the dlib internals.  A lot of the API
          decisions are based on what makes the interface a user needs to
          implement to create new layers as simple as possible.  In particular,
          designing the API in this compile-time static way makes it simple for
          these use cases.  
          <p>
             Here is an example of one problem it addresses.  Since dlib
             exposes the entire network architecture to the C++ type system we
             can get automatic serialization of networks.  Without this, we
             would have to resort to the kind of hacky global layer registry
             used in other tools that compose networks entirely at runtime.
          </p>
          <p>
             Another nice feature is that we get to use C++11 alias template
             statements to create network sub-blocks, which we can then use to easily
             define very large networks.  There are examples of this in <a
             href="dnn_introduction2_ex.cpp.html">this example program</a>.  It
             should also be pointed out that it takes days or even weeks to
             train one network.  So it isn't as if you will be writing a
             program that loops over large numbers of networks and trains them
             all.  This makes the time needed to recompile a program to change
             the network irrelevant compared to the entire training time.
             Moreover, there are plenty of compile time constructs in C++ you
             can use to enumerate network architectures (e.g. loop
             over filter widths) if you really wanted to do so.  
          </p>
          <p>
             All that said, if you think you found a compelling use case that isn't supported
             by the current API feel free to post a <a href="https://github.com/davisking/dlib/issues">github</a> issue.
          </p>
      </question>
   </questions>

   <!-- ************************************************************************* -->


</doc>
